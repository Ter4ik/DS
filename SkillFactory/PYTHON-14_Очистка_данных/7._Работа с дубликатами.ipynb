{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>preschool_quota</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>school_quota</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>...</th>\n",
       "      <th>office_km</th>\n",
       "      <th>additional_education_km</th>\n",
       "      <th>preschool_km</th>\n",
       "      <th>big_church_km</th>\n",
       "      <th>church_synagogue_km</th>\n",
       "      <th>theater_km</th>\n",
       "      <th>museum_km</th>\n",
       "      <th>ecology</th>\n",
       "      <th>mosque_count_1000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bibirevo</td>\n",
       "      <td>5001.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11065.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637189</td>\n",
       "      <td>0.947962</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.625783</td>\n",
       "      <td>0.628187</td>\n",
       "      <td>14.053047</td>\n",
       "      <td>7.389498</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>5850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nagatinskij Zaton</td>\n",
       "      <td>3119.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688796</td>\n",
       "      <td>1.072315</td>\n",
       "      <td>0.273345</td>\n",
       "      <td>0.967821</td>\n",
       "      <td>0.471447</td>\n",
       "      <td>6.829889</td>\n",
       "      <td>0.709260</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Tekstil'shhiki</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5580.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.543049</td>\n",
       "      <td>0.391957</td>\n",
       "      <td>0.158072</td>\n",
       "      <td>3.178751</td>\n",
       "      <td>0.755946</td>\n",
       "      <td>4.273200</td>\n",
       "      <td>3.156423</td>\n",
       "      <td>poor</td>\n",
       "      <td>0</td>\n",
       "      <td>5700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Mitino</td>\n",
       "      <td>6839.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17063.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934273</td>\n",
       "      <td>0.892674</td>\n",
       "      <td>0.236455</td>\n",
       "      <td>1.031777</td>\n",
       "      <td>1.561505</td>\n",
       "      <td>16.990677</td>\n",
       "      <td>16.041521</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>13100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basmannoe</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7770.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077901</td>\n",
       "      <td>0.810801</td>\n",
       "      <td>0.376838</td>\n",
       "      <td>0.378756</td>\n",
       "      <td>0.121681</td>\n",
       "      <td>1.112486</td>\n",
       "      <td>1.800125</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>16331452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  full_sq  life_sq  floor           sub_area  preschool_quota  \\\n",
       "0   1       43     27.0    4.0           Bibirevo           5001.0   \n",
       "1   2       34     19.0    3.0  Nagatinskij Zaton           3119.0   \n",
       "2   3       43     29.0    2.0     Tekstil'shhiki           1463.0   \n",
       "3   4       89     50.0    9.0             Mitino           6839.0   \n",
       "4   5       77     77.0    4.0          Basmannoe           3240.0   \n",
       "\n",
       "   preschool_education_centers_raion  school_quota  \\\n",
       "0                                  5       11065.0   \n",
       "1                                  5        6237.0   \n",
       "2                                  4        5580.0   \n",
       "3                                  9       17063.0   \n",
       "4                                  7        7770.0   \n",
       "\n",
       "   school_education_centers_raion  school_education_centers_top_20_raion  ...  \\\n",
       "0                               5                                      0  ...   \n",
       "1                               8                                      0  ...   \n",
       "2                               7                                      0  ...   \n",
       "3                              10                                      0  ...   \n",
       "4                               9                                      0  ...   \n",
       "\n",
       "   office_km  additional_education_km  preschool_km  big_church_km  \\\n",
       "0   0.637189                 0.947962      0.177975       0.625783   \n",
       "1   0.688796                 1.072315      0.273345       0.967821   \n",
       "2   1.543049                 0.391957      0.158072       3.178751   \n",
       "3   0.934273                 0.892674      0.236455       1.031777   \n",
       "4   0.077901                 0.810801      0.376838       0.378756   \n",
       "\n",
       "   church_synagogue_km  theater_km  museum_km    ecology mosque_count_1000  \\\n",
       "0             0.628187   14.053047   7.389498       good                 0   \n",
       "1             0.471447    6.829889   0.709260  excellent                 0   \n",
       "2             0.755946    4.273200   3.156423       poor                 0   \n",
       "3             1.561505   16.990677  16.041521       good                 0   \n",
       "4             0.121681    1.112486   1.800125  excellent                 0   \n",
       "\n",
       "  price_doc  \n",
       "0   5850000  \n",
       "1   6000000  \n",
       "2   5700000  \n",
       "3  13100000  \n",
       "4  16331452  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sber_data = pd.read_csv('data/sber_data.csv')\n",
    "sber_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                         ДУБЛИКАТЫ\n",
    "\n",
    "Иногда данные могут содержать повторяющиеся записи (дубликаты).\n",
    "\n",
    "Дубликатами называются записи, для которых значения (всех или большинства) признаков совпадают. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                         ОБНАРУЖЕНИЕ И ЛИКВИДАЦИЯ ДУБЛИКАТОВ\n",
    "\n",
    "Способ обнаружения дубликатов зависит от того, что именно вы считаете дубликатом. Например, за дубликаты можно посчитать записи, у которых совпадают все признаки или их часть. Если в таблице есть столбец с уникальным идентификатором (id), вы можете попробовать поискать дубликаты по нему: одинаковые записи могут иметь одинаковый id.\n",
    "\n",
    "✍️ Проверим, есть у нас такие записи: для этого сравним число уникальных значений в столбце id с числом строк. Число уникальных значений вычислим с помощью метода nunique():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sber_data['id'].nunique() == sber_data.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде бы всё в порядке: каждой записи в таблице соответствует свой уникальный идентификатор. Но это ещё не означает, что в таблице нет дубликатов!\n",
    "\n",
    "Столбец с id задаёт каждой строке свой уникальный номер, поэтому сама по себе каждая строка является уникальной. Однако содержимое других столбцов может повторяться.\n",
    "\n",
    "```Чтобы отследить дубликаты, можно воспользоваться методом duplicated(), который возвращает булеву маску для фильтрации. Для записей, у которых совпадают признаки, переданные методу, он возвращает True, для остальных — False.```\n",
    "\n",
    "```У метода есть параметр subset — список признаков, по которым производится поиск дубликатов. По умолчанию используются все столбцы в DataFrame и ищутся полные дубликаты.```\n",
    "\n",
    "✍️ Найдём число полных дубликатов таблице sber_data. Предварительно создадим список столбцов dupl_columns, по которым будем искать совпадения (все столбцы, не включая id). </br>\n",
    "Создадим маску дубликатов с помощью метода duplicated() и произведём фильтрацию. Результат заносим в переменную sber_duplicates. Выведем число строк в результирующем DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число найденных дубликатов: 562\n"
     ]
    }
   ],
   "source": [
    "dupl_columns = list(sber_data.columns) # создадим список столбцов dupl_columns, по которым будем искать совпадения\n",
    "dupl_columns.remove('id') # исключим id\n",
    "mask = sber_data.duplicated(subset=dupl_columns) # Создадим маску дубликатов с помощью метода duplicated()и произведём фильтрацию\n",
    "sber_duplicates = sber_data[mask] #  Результат заносим в переменную sber_duplicates\n",
    "print(f'Число найденных дубликатов: {sber_duplicates.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, 562 строки в таблице являются полными копиями других записей. Ручной поиск совпадающих строк по 30 тысячам записей был бы практически невыполним, а с помощью pandas мы быстро, а главное, легко обнаружили дублирующиеся данные!\n",
    "\n",
    "Теперь нам необходимо от них избавиться. Для этого легче всего воспользоваться методом drop_duplicates(), который удаляет повторяющиеся записи из таблицы. \n",
    "\n",
    "✍️ Создадим новую таблицу sber_dedupped, которая будет версией исходной таблицы, очищенной от полных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результирующее число записей: 29909\n"
     ]
    }
   ],
   "source": [
    "sber_dedupped = sber_data.drop_duplicates(subset=dupl_columns)\n",
    "print(f'Результирующее число записей: {sber_dedupped.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                  HЕИНФОРМАТИВНЫЕ ПРИЗНАКИ\n",
    "\n",
    "Отсутствием новой и полезной информации могут «похвастаться» не только отдельные записи в таблице, но и целые признаки.\n",
    "_______________________________\n",
    "```Неинформативными называются признаки, в которых большая часть строк содержит одинаковые значения (например, пол клиентов в мужском барбершопе), либо наоборот — признак, в котором для большинства записей значения уникальны (например, номер телефона клиента). ```\n",
    "______________________________________\n",
    "Мы уже сталкивались с неинформативными признаками. Вспомните датасет о домах в Мельбурне, где был признак адреса дома с уникальным значением для каждого дома. \n",
    "\n",
    "                                        ЧЕМ ОПАСНЫ НЕИНФОРМАТИВНЫЕ ПРИЗНАКИ?\n",
    "\n",
    "Такие признаки не играют роли при моделировании и лишь засоряют таблицу, увеличивая размерность данных. Они усиливают уже знакомое нам проклятие размерности, которое увеличивает время обучения модели и потенциально может снизить ее качество. \n",
    "\n",
    "Поэтому от таких признаков необходимо безжалостно избавляться.\n",
    "\n",
    "                                         ОБНАРУЖЕНИЕ И ЛИКВИДАЦИЯ НЕИНФОРМАТИВНЫХ ПРИЗНАКОВ\n",
    "\n",
    "Чтобы считать признак неинформативным, прежде всего нужно задать какой-то определённый порог. Например, часто используют пороги в 0.95 и 0.99. Это означает: признак неинформативен, если в нем 95 % (99 %) одинаковых значений или же 95 % (99 %) данных полностью уникальны.\n",
    "\n",
    "К сожалению, в pandas пока нет волшебной палочки, которая мгновенно бы выдавала список столбцов, обладающих низкой информативностью. Однако процедура их поиска легко реализуется вручную."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                   Разберём алгоритм:\n",
    "\n",
    "* → Создаём пустой список low_information_cols, куда будем добавлять названия признаков, которые мы посчитаем неинформативными.\n",
    "\n",
    "* → В цикле пройдёмся по всем именам столбцов в таблице и для каждого будем совершать следующие действия:\n",
    "\n",
    "* рассчитаем top_freq — наибольшую относительную частоту с помощью метода value_counts() с параметром normalize=True. Метод вернёт долю от общих данных, которую занимает каждое уникальное значение в признаке.\n",
    "Например, для столбца oil_chemistry_raion (нефтехимический район) результат будет следующим:</br>\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/26d5cb5e089bb2fb7a342c000aa81599/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-unit-1-mod-14-29.png)</br>\n",
    "Отсюда нам нужен максимум.\n",
    "\n",
    "* рассчитаем nunique_ratio — отношение числа уникальных значений в столбце к размеру всего столбца. Число уникальных значений в столбце получим с помощью метода nunique(), а размер признака — с помощью метода count(). Например, для столбца id число уникальных значений — 30471; оно же равно размеру таблицы. Поэтому результат отношения будет 1.\n",
    "* сравним каждое из полученных чисел с пороговым значением (у нас это 0.95) и добавим в список неинформативных признаков, если условие истинно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 100.0% уникальных значений\n",
      "oil_chemistry_raion: 99.03% одинаковых значений\n",
      "railroad_terminal_raion: 96.27% одинаковых значений\n",
      "nuclear_reactor_raion: 97.17% одинаковых значений\n",
      "big_road1_1line: 97.44% одинаковых значений\n",
      "mosque_count_1000: 98.08% одинаковых значений\n"
     ]
    }
   ],
   "source": [
    "# список неинформативных признаков\n",
    "low_information_cols = [] # Создаём пустой список low_information_cols, куда будем добавлять названия признаков, которые мы посчитаем неинформативными\n",
    "\n",
    "#цикл по всем столбцам\n",
    "for col in sber_data.columns:\n",
    "    #наибольшая относительная частота в признаке\n",
    "    top_freq = sber_data[col].value_counts(normalize=True).max()\n",
    "    #доля уникальных значений от размера признака\n",
    "    nunique_ratio = sber_data[col].nunique() / sber_data[col].count()\n",
    "    # сравниваем наибольшую частоту с порогом\n",
    "    if top_freq > 0.95:\n",
    "        low_information_cols.append(col)\n",
    "        print(f'{col}: {round(top_freq*100, 2)}% одинаковых значений')\n",
    "    # сравниваем долю уникальных значений с порогом\n",
    "    if nunique_ratio > 0.95:\n",
    "        low_information_cols.append(col)\n",
    "        print(f'{col}: {round(nunique_ratio*100, 2)}% уникальных значений')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы нашли шесть неинформативных признаков. Теперь можно удалить их с помощью метода drop(), передав результирующий список в его аргументы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Результирующее число признаков: 55'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "information_sber_data = sber_data.drop(low_information_cols, axis=1)\n",
    "display(f'Результирующее число признаков: {information_sber_data.shape[1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                           ВАЖНОСТЬ ПРИЗНАКОВ\n",
    "\n",
    "На самом деле информативность признаков определяется не только числом уникальных значений, но и их влиянием на целевой признак (тот, который мы хотим предсказать). Это называется важностью признака. \n",
    "\n",
    "```Признаки, которые обладают низкой важностью, называют нерелевантными признаками. ```\n",
    "\n",
    "Например, если бы в наших данных о квартирах был признак, содержащий информацию о температуре воздуха за окном, он был бы нерелевантным.\n",
    "\n",
    "Нерелевантные признаки могут быть не такими очевидными. В таких случаях применяются более сложные способы их поиска с использованием статистики и моделей машинного обучения. Мы поговорим об этом позже, когда вплотную подойдём к Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
